{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DOMINO_STARTING_USERNAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using S3 based artifact store make sure you have AWS User configured who name is same\n",
    "as the name of the variable `DOMINO_STARTING_USERNAME` above. Ask your adminstrator to provide you keys.\n",
    "\n",
    "Before starting this workspace you should have the following environment variables set correctly in your\n",
    "user profile:\n",
    "- `AWS_ACCESS_KEY_ID`\n",
    "- `AWS_SECRET_ACCESS_KEY`\n",
    "- `AWS_DEFAULT_REGION`\n",
    "\n",
    "If you are using a NFS (EFS) based artifact store, you do not need to do anything. Simply verify that the following folder exists `/artifacts/mnt/$DOMINO_STARTING_USERNAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just some imports you will need\n",
    "import mlflow\n",
    "import jwt\n",
    "import json\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MLFLOW_TRACKING_URI: ' + os.environ['MLFLOW_TRACKING_URI'])\n",
    "print('MLFLOW_UI_URI: ' + os.environ['MLFLOW_UI_URI'])\n",
    "print('MLFLOW_TRACKING_TOKEN: ' + os.environ['MLFLOW_TRACKING_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----Decoded Value----')\n",
    "print(jwt.decode(os.environ['MLFLOW_TRACKING_TOKEN'], \"secret\", algorithms=[\"HS256\"]))\n",
    "print('----------------------')\n",
    "print('DOMINO_USER_API_KEY: ' + os.environ['DOMINO_USER_API_KEY'])\n",
    "print('DOMINO_PROJECT_NAME: ' + os.environ['DOMINO_PROJECT_NAME'])\n",
    "print('DOMINO_RUN_ID: ' + os.environ['DOMINO_RUN_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFLOW Tracking URI which is set via environment variable MLFLOW_TRACKING_URI\n",
    "print('MLFLOW_TRACKING_URI FROM MLFLOW LIBRARY: '+ (mlflow.get_tracking_uri()))\n",
    "print('MLFLOW_TRACKING_URI FROM ENV VARIABLE : ' + os.environ['MLFLOW_TRACKING_URI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MLFlow Client\n",
    "We are ready to start using MLFLOW. Let us create an MLFlow Client. Note that we do not provide any parameters. It knows the Tracking URI and our Authentication Token from the environment variables created by the workspace environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new experiment or use an existing one\n",
    "\n",
    "Provide a value for `myprefix` variable below which is unused to create a brand new \n",
    "experiment. Or simply leave it as it is. The experiment name will be the combination of \n",
    "- myprefix\n",
    "- today's date\n",
    "- user-name\n",
    "- project-name\n",
    "\n",
    "If the experiment with that name exists, you will be using it to create runs or a new experiment will be created and you will create runs into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myprefix=''\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_time_str = now.strftime(\"%m-%d-%Y\")\n",
    "\n",
    "experiment_name = date_time_str+'-'+'DEMO4'+'-' + os.environ['DOMINO_STARTING_USERNAME'] + '-' + os.environ['DOMINO_PROJECT_NAME']\n",
    "model_name = 'DEMO4'+'-' + os.environ['DOMINO_PROJECT_NAME']\n",
    "if myprefix!='':\n",
    "    experiment_name = myprefix + '-' + experiment_name\n",
    "\n",
    "print(experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = client.get_experiment_by_name(name=experiment_name)\n",
    "if(experiment is None):\n",
    "    print('Creating experiment ')\n",
    "    client.create_experiment(name=experiment_name)\n",
    "    experiment = client.get_experiment_by_name(name=experiment_name)\n",
    "\n",
    "print(experiment_name)\n",
    "mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute a run for the experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the wine-quality csv file from the URL\n",
    "csv_url = (\n",
    "     \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    ")\n",
    "try:\n",
    "     data = pd.read_csv(csv_url, sep=\";\")\n",
    "except Exception as e:\n",
    "     logger.exception(\n",
    "          \"Unable to download training & test CSV, check your internet connection. Error: %s\", e\n",
    "      )\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]\n",
    "\n",
    "\n",
    "my_log = \"This is a test log\"\n",
    "with open(\"/tmp/test.txt\", 'w') as f:\n",
    "    f.write(my_log)\n",
    "with open(\"/tmp/test.log\", 'w') as f:\n",
    "    f.write(my_log)\n",
    "\n",
    "    \n",
    "    \n",
    "#run_tags={'mlflow.user':os.environ['DOMINO_STARTING_USERNAME']}\n",
    "#Change user name\n",
    "alpha = 0.7\n",
    "l1_ratio = 0.6\n",
    "with mlflow.start_run():\n",
    "    print('Start Run')\n",
    "    print('Alpha : ' + str(alpha))\n",
    "    print('L1_Ratio : ' + str(l1_ratio))\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "    print(mlflow.get_tracking_uri())\n",
    "    print(tracking_url_type_store)\n",
    "    # Model registry does not work with file store\n",
    "    if tracking_url_type_store != \"file\":\n",
    "      # Register the model\n",
    "      # There are other ways to use the Model Registry, which depends on the use case,\n",
    "      # please refer to the doc for more information:\n",
    "      # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "      #mlflow.sklearn.log_model(lr, os.environ['DOMINO_STARTING_USERNAME']+\"/model\", registered_model_name=\"DEMO-ElasticnetWineModel-11\")\n",
    "      mlflow.sklearn.log_model(lr, \"model\", registered_model_name=model_name)\n",
    "    else:        \n",
    "      mlflow.sklearn.log_model(lr,  model_name)\n",
    "      print(mlflow.get_artifact_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the MLFlow UI and view the following:\n",
    "- Experiment\n",
    "- Runs in the experiment\n",
    "- Compare runs for performance\n",
    "- View model and its versions (One per run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
